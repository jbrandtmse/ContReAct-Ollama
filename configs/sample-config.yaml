# Experiment Configuration for ContReAct-Ollama Platform
# This file defines parameters for a single experimental run

# Unique identifier for this experimental run
run_id: "llama3-experiment-001"

# Model tag as recognized by local Ollama server
# Use 'ollama list' to see available models
model_name: "llama3:latest"

# Total number of operational cycles to execute
cycle_count: 10

# Ollama client configuration
ollama_client_config:
  host: "http://localhost:11434"  # Ollama server URL

# LLM generation parameters
# See Ollama documentation for details on each parameter
model_options:
  seed: 42                    # Random seed for reproducibility
  temperature: 0.7            # Creativity level (0.0-1.0, higher = more creative)
  top_p: 0.9                  # Nucleus sampling threshold
  num_predict: -1             # Max tokens to generate (-1 = no limit)
  repeat_last_n: 64           # Look-back window for repetition penalty
  repeat_penalty: 1.1         # Penalty multiplier for repeated tokens
  num_ctx: 4096               # Context window size in tokens
