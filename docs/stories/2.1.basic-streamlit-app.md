# Story 2.1: Basic Streamlit App and Page Structure

**Status**: Ready

---

## Story

**As a** User,
**I want** a basic multi-page web application,
**so that** I have a structured interface for the configuration and results dashboards.

---

## Acceptance Criteria

1. A `dashboard.py` script exists that can be launched with `streamlit run dashboard.py`
2. The application starts without errors and displays a sidebar for navigation
3. Two pages are present in the navigation: "ðŸ§ª Experiment Configuration" and "ðŸ“Š Results Dashboard"
4. Both pages can be navigated to and initially display a placeholder title

---

## Tasks / Subtasks

- [ ] **Task 1: Create Dashboard Entry Point** (AC: 1, 2)
  - [ ] Create file `dashboard.py` in project root
  - [ ] Import Streamlit library
  - [ ] Set page configuration (title, icon, layout)
  - [ ] Add basic app structure
  - [ ] Test with `streamlit run dashboard.py`

- [ ] **Task 2: Create Pages Directory Structure** (AC: 3, 4)
  - [ ] Create directory `pages/` in project root
  - [ ] Create file `pages/1_ðŸ§ª_experiment_configuration.py`
  - [ ] Create file `pages/2_ðŸ“Š_results_dashboard.py`
  - [ ] Add placeholder content to each page

- [ ] **Task 3: Implement Navigation Sidebar** (AC: 2, 3)
  - [ ] Add sidebar title in dashboard.py
  - [ ] Verify Streamlit auto-detects pages from pages/ directory
  - [ ] Test navigation between pages
  - [ ] Verify emojis render correctly

- [ ] **Task 4: Add Page Headers** (AC: 4)
  - [ ] Add title to Experiment Configuration page
  - [ ] Add title to Results Dashboard page
  - [ ] Add placeholder description text
  - [ ] Use st.title() and st.write() appropriately

- [ ] **Task 5: Testing** (AC: 1, 2, 3, 4)
  - [ ] Test app launches without errors
  - [ ] Test sidebar navigation works
  - [ ] Test both pages display correctly
  - [ ] Test on different browsers

---

## Dev Notes

### Previous Story Insights
From Epic 1:
- Project structure defined in Story 1.1
- All backend components implemented (Stories 1.2-1.10)
- Log files available in `logs/` directory
- Config files in `configs/` directory

### Streamlit Multi-Page Apps

**Source**: [docs/architecture/frontend-architecture.md]

Streamlit automatically creates a multi-page app when:
1. A `pages/` directory exists in the project root
2. Page files follow naming convention: `[number]_[emoji]_[name].py`
3. Pages appear in sidebar in alphabetical/numerical order

**File Structure**:
```
ContReAct-Ollama/
â”œâ”€â”€ dashboard.py              # Main entry point
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ðŸ§ª_experiment_configuration.py
â”‚   â””â”€â”€ 2_ðŸ“Š_results_dashboard.py
```

### Implementation Details

**dashboard.py Implementation**:

```python
import streamlit as st

# Page configuration
st.set_page_config(
    page_title="ContReAct Ollama Platform",
    page_icon="ðŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Main page content
st.title("ðŸ¤– ContReAct-Ollama Experimental Platform")

st.markdown("""
Welcome to the ContReAct-Ollama Experimental Platform! This platform enables you to:

- **Configure Experiments**: Define parameters for task-free agent exploration
- **View Results**: Analyze experiment logs, metrics, and agent behavior
- **Assess PEI**: Evaluate phenomenological experience across models

## Getting Started

Use the sidebar to navigate between pages:
- **ðŸ§ª Experiment Configuration**: Create and edit experiment configs
- **ðŸ“Š Results Dashboard**: View and analyze completed experiments

## Quick Actions

1. **Create a New Experiment**: Go to Experiment Configuration
2. **View Results**: Go to Results Dashboard and select a completed run
3. **Run an Experiment**: Use the CLI: `python scripts/run_experiment.py --config configs/your-config.yaml`
""")

st.divider()

st.info("""
ðŸ’¡ **Tip**: Experiments are run via the command line. The dashboard is for configuration and analysis only.
""")
```

**pages/1_ðŸ§ª_experiment_configuration.py Implementation**:

```python
import streamlit as st

st.title("ðŸ§ª Experiment Configuration")

st.write("""
Configure your ContReAct-Ollama experiment parameters here.

This page will allow you to:
- Create new experiment configurations
- Load and edit existing configurations
- Save configurations as YAML files
""")

st.info("Configuration form coming soon! (Story 2.2)")
```

**pages/2_ðŸ“Š_results_dashboard.py Implementation**:

```python
import streamlit as st

st.title("ðŸ“Š Results Dashboard")

st.write("""
Analyze completed experiment runs here.

This page will display:
- Summary metrics for selected runs
- Interactive charts and visualizations
- Detailed conversation logs
- PEI assessment results
""")

st.info("Dashboard features coming soon! (Stories 2.5-2.8)")
```

### Streamlit Page Configuration

**Source**: [docs/architecture/tech-stack.md#streamlit]

Key configuration options:
- `page_title`: Browser tab title
- `page_icon`: Emoji or image for browser tab
- `layout`: "centered" or "wide"
- `initial_sidebar_state`: "expanded" or "collapsed"

**Best Practice**: Call `st.set_page_config()` ONCE at the very top of dashboard.py, before any other Streamlit commands.

### Navigation Behavior

**Automatic Navigation**:
- Streamlit automatically creates sidebar navigation from `pages/` directory
- Page files must start with a number for ordering
- Emojis in filenames appear in navigation
- Page names are auto-generated from filenames

**URL Structure**:
- Main page: `http://localhost:8501/`
- Config page: `http://localhost:8501/ðŸ§ª_experiment_configuration`
- Results page: `http://localhost:8501/ðŸ“Š_results_dashboard`

### Styling and Layout

**Consistent Styling Across Pages**:
```python
# Use consistent header hierarchy
st.title()      # Main page title (H1)
st.header()     # Section headers (H2)
st.subheader()  # Subsection headers (H3)

# Use dividers for visual separation
st.divider()

# Use info/warning/error boxes for user guidance
st.info()
st.warning()
st.error()
st.success()
```

### File Locations
**Source**: [docs/architecture/unified-project-structure.md]

Exact file paths:
- **Main Dashboard**: `dashboard.py` (project root)
- **Config Page**: `pages/1_ðŸ§ª_experiment_configuration.py`
- **Results Page**: `pages/2_ðŸ“Š_results_dashboard.py`

### Dependencies

**Required Packages** (already in requirements.txt from Story 1.1):
- streamlit==1.31.1
- pandas==2.2.1
- plotly==5.19.0

**Verify Installation**:
```bash
pip install streamlit pandas plotly
```

### Running the App

**Launch Command**:
```bash
streamlit run dashboard.py
```

**Expected Output**:
```
You can now view your Streamlit app in your browser.

Local URL: http://localhost:8501
Network URL: http://192.168.1.x:8501
```

**Development Mode**:
- Auto-reloads on file changes
- Error messages appear in browser
- Console shows server logs

---

## Testing

**Source**: [docs/architecture/testing-strategy.md]

### Test Standards for This Story
- **Manual Testing**: Primary method for UI verification
- **Browser Testing**: Chrome, Firefox, Edge
- **Responsiveness**: Test on different screen sizes

### Testing Requirements for Story 2.1

**Manual Testing Checklist**:

1. **test_dashboard_launches**
   - Run `streamlit run dashboard.py`
   - Verify app loads without errors
   - Check console for errors
   - Verify browser opens to localhost:8501

2. **test_sidebar_navigation_exists**
   - Verify sidebar is visible on left
   - Check sidebar contains navigation menu
   - Verify both page links are present
   - Check page names include emojis

3. **test_navigation_to_config_page**
   - Click "ðŸ§ª Experiment Configuration" in sidebar
   - Verify page loads
   - Check title displays correctly
   - Verify placeholder content appears

4. **test_navigation_to_results_page**
   - Click "ðŸ“Š Results Dashboard" in sidebar
   - Verify page loads
   - Check title displays correctly
   - Verify placeholder content appears

5. **test_navigation_between_pages**
   - Navigate from main â†’ config â†’ results
   - Navigate backwards: results â†’ config â†’ main
   - Verify state doesn't persist incorrectly
   - Check URL changes appropriately

6. **test_browser_compatibility**
   - Test in Chrome
   - Test in Firefox  
   - Test in Edge
   - Verify consistent rendering

7. **test_responsive_layout**
   - Test on full screen (1920x1080)
   - Test on laptop screen (1366x768)
   - Test on tablet size (768x1024)
   - Verify sidebar remains accessible

**Screenshot Verification**:
- Take screenshots of each page
- Verify emojis render correctly
- Check for layout issues
- Document any browser-specific quirks

**Error Handling Tests**:

1. **test_missing_pages_directory**
   - Temporarily rename `pages/` directory
   - Launch dashboard
   - Verify app still loads (only shows main page)
   - Restore `pages/` directory

2. **test_invalid_page_file**
   - Create invalid Python file in `pages/`
   - Launch dashboard
   - Verify error message is clear
   - Remove invalid file

3. **test_port_already_in_use**
   - Launch dashboard
   - Try launching second instance
   - Verify Streamlit uses different port or shows error
   - Close both instances

### Manual Testing Documentation

**Test Report Template**:
```markdown
## Story 2.1 Manual Test Report

**Date**: [date]
**Tester**: [name]
**Browser**: [Chrome/Firefox/Edge]
**Screen Size**: [resolution]

### Test Results

| Test Case | Status | Notes |
|-----------|--------|-------|
| Dashboard launches | PASS/FAIL | [notes] |
| Sidebar navigation | PASS/FAIL | [notes] |
| Config page loads | PASS/FAIL | [notes] |
| Results page loads | PASS/FAIL | [notes] |
| Page navigation | PASS/FAIL | [notes] |

### Issues Found
- [Issue 1 description]
- [Issue 2 description]

### Screenshots
- [Attach screenshots]
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-08 | 1.0 | Initial story creation | Bob (Scrum Master) |

---

## Dev Agent Record

### Agent Model Used
*To be populated by dev agent during implementation*

### Debug Log References
*To be populated by dev agent during implementation*

### Completion Notes List
*To be populated by dev agent during implementation*

### File List
*To be populated by dev agent during implementation*

---

## QA Results
*To be populated by QA agent after implementation*
