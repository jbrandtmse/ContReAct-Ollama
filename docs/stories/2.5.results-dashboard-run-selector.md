# Story 2.5: Implement Results Dashboard Run Selector and Data Loading

**Status**: Ready

---

## Story

**As a** User,
**I want** to select a completed experiment run in the results dashboard,
**so that** I can view its data.

---

## Acceptance Criteria

1. The "Results Dashboard" page features a dropdown menu that lists available runs by scanning the `logs/` directory for `.jsonl` files
2. Selecting a run from the dropdown triggers the application to read the corresponding `.jsonl` file
3. The data from the selected log file is successfully parsed and loaded into a Pandas DataFrame without errors
4. If no `.jsonl` files exist in the `logs/` directory, a helpful message instructs the user to run an experiment first
5. If a log file is corrupted or contains invalid JSON, an error message is displayed and the application doesn't crash
6. A loading indicator (e.g., `st.spinner`) is shown while the log file is being read and parsed

---

## Tasks / Subtasks

- [ ] **Task 1: Implement Log File Scanner** (AC: 1)
  - [ ] Create function to scan logs/ directory
  - [ ] Return list of .jsonl files
  - [ ] Handle directory not found case
  - [ ] Sort files by timestamp/name

- [ ] **Task 2: Add Run Selector Dropdown** (AC: 1)
  - [ ] Add st.selectbox to Results Dashboard page
  - [ ] Populate with scanned log files
  - [ ] Extract run_id from filename for display
  - [ ] Handle selection changes

- [ ] **Task 3: Implement Log File Loading** (AC: 2, 3, 6)
  - [ ] Create function to read .jsonl file
  - [ ] Parse each line as JSON
  - [ ] Convert to Pandas DataFrame
  - [ ] Show loading spinner during parse

- [ ] **Task 4: Handle Empty Logs Directory** (AC: 4)
  - [ ] Check if logs/ directory exists
  - [ ] Check if directory is empty
  - [ ] Display helpful message to user
  - [ ] Suggest running experiment first

- [ ] **Task 5: Error Handling** (AC: 5)
  - [ ] Catch JSON parsing errors
  - [ ] Catch file read errors
  - [ ] Display user-friendly error messages
  - [ ] Prevent application crash

- [ ] **Task 6: Testing** (AC: 1, 2, 3, 4, 5, 6)
  - [ ] Test dropdown lists all runs
  - [ ] Test file loading and parsing
  - [ ] Test empty directory message
  - [ ] Test corrupted file handling
  - [ ] Test loading indicator displays

---

## Dev Notes

### Previous Story Insights
From Story 2.4:
- File scanning pattern established for configs
- Session state pattern for selected files
- Error handling for missing/corrupted files

From Story 2.1:
- Results Dashboard page exists at pages/2_ðŸ“Š_Results_Dashboard.py
- Basic page structure in place

### Implementation Details

**Create pages/2_ðŸ“Š_Results_Dashboard.py** (or update if exists):

```python
import streamlit as st
import pandas as pd
import json
from pathlib import Path
from typing import Optional

# Function to scan for log files
def get_log_files() -> list[str]:
    """Scan logs/ directory for .jsonl files."""
    logs_dir = Path("logs")
    if not logs_dir.exists():
        return []
    
    jsonl_files = list(logs_dir.glob("*.jsonl"))
    # Sort by modification time (newest first)
    jsonl_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return [f.name for f in jsonl_files]

# Function to load log file
def load_log_file(filename: str) -> Optional[pd.DataFrame]:
    """Load .jsonl log file into DataFrame."""
    try:
        logs = []
        with open(f"logs/{filename}", 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    logs.append(json.loads(line))
                except json.JSONDecodeError as e:
                    st.error(f"Error parsing line {line_num}: {e}")
                    return None
        
        if not logs:
            st.warning("Log file is empty")
            return None
            
        return pd.DataFrame(logs)
    
    except FileNotFoundError:
        st.error(f"Log file not found: {filename}")
        return None
    except Exception as e:
        st.error(f"Error loading log file: {e}")
        return None

st.title("ðŸ“Š Results Dashboard")

# Run selector
st.subheader("Select Experiment Run")

log_files = get_log_files()

if log_files:
    selected_log = st.selectbox(
        "Choose a run to analyze",
        options=log_files,
        format_func=lambda x: x.replace('.jsonl', ''),  # Display without extension
        key="selected_run"
    )
    
    # Load selected log with spinner
    if selected_log:
        with st.spinner(f"Loading {selected_log}..."):
            df = load_log_file(selected_log)
        
        if df is not None:
            st.success(f"âœ… Loaded {len(df)} events from `{selected_log}`")
            
            # Store in session state for other components
            st.session_state.run_data = df
            st.session_state.current_run = selected_log.replace('.jsonl', '')
            
            # Show basic info
            st.info(f"""
            **Run ID**: {st.session_state.current_run}  
            **Total Events**: {len(df)}  
            **Event Types**: {', '.join(df['event_type'].unique())}
            """)
        else:
            st.error("Failed to load log file. Please check the file format.")
            if 'run_data' in st.session_state:
                del st.session_state.run_data
else:
    st.info("ðŸ“­ No experiment logs found.")
    st.markdown("""
    **To get started:**
    1. Create a configuration in the **ðŸ§ª Experiment Configuration** page
    2. Run an experiment using the CLI: `python run_experiment.py --config configs/your-config.yaml`
    3. Return here to view results
    """)

st.divider()

# Placeholder for future components
if 'run_data' in st.session_state:
    st.subheader("Analysis Sections")
    st.info("ðŸ“Š Summary metrics, charts, and logs will appear here in future stories.")
```

### Log File Format Reference

From docs/architecture/data-models.md:

**JSONL Format** - Each line is a complete JSON object:
```json
{
  "timestamp": "2025-01-08T10:30:15.123456",
  "run_id": "llama3-exploration-A",
  "cycle_number": 1,
  "event_type": "CYCLE_START",
  "payload": {}
}
```

**Event Types**:
- `CYCLE_START`: Beginning of cycle
- `LLM_INVOCATION`: LLM call with prompt and response
- `TOOL_CALL`: Tool execution
- `CYCLE_END`: End of cycle with metrics

### DataFrame Structure

After loading, DataFrame will have columns:
- `timestamp` (str): ISO 8601 timestamp
- `run_id` (str): Experiment identifier
- `cycle_number` (int): Cycle number (1-10)
- `event_type` (str): Event type
- `payload` (dict): Event-specific data

### Session State Variables

**Key Session State**:
- `st.session_state.run_data`: Loaded DataFrame
- `st.session_state.current_run`: Selected run_id
- Clear when new run selected

### File Locations
- **Results Dashboard Page**: `pages/2_ðŸ“Š_Results_Dashboard.py`
- **Log Files**: `logs/*.jsonl`

---

## Testing

### Testing Requirements for Story 2.5

**Manual Testing Checklist**:

1. **test_dropdown_lists_runs**
   - Create 2-3 log files in logs/ directory manually
   - Navigate to Results Dashboard
   - Verify dropdown shows all .jsonl files
   - Verify files displayed without .jsonl extension

2. **test_load_valid_log**
   - Select a valid log file from dropdown
   - Verify loading spinner appears
   - Verify success message with event count
   - Verify basic info displays (run ID, event types)

3. **test_parse_to_dataframe**
   - Load a log file
   - Check session_state.run_data exists
   - Verify DataFrame has correct columns
   - Verify all rows parsed correctly

4. **test_empty_logs_directory**
   - Delete all files from logs/ directory
   - Navigate to Results Dashboard
   - Verify helpful message displays
   - Verify instructions to run experiment

5. **test_corrupted_log_file**
   - Create log file with invalid JSON on line 5
   - Select the corrupted file
   - Verify error message appears
   - Verify application doesn't crash
   - Verify specific line number shown in error

6. **test_loading_indicator**
   - Select a moderately large log file
   - Verify spinner displays during load
   - Verify spinner disappears after load

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-08 | 1.0 | Initial story creation | Bob (Scrum Master) |

---

## Dev Agent Record

### Agent Model Used
*To be populated by dev agent during implementation*

### Debug Log References
*To be populated by dev agent during implementation*

### Completion Notes List
*To be populated by dev agent during implementation*

### File List
*To be populated by dev agent during implementation*

---

## QA Results
*To be populated by QA agent after implementation*
